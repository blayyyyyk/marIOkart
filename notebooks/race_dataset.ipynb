{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53096355-48a7-44d0-a3cb-8676ca2f1391",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22d7f4fb-da54-4c00-b9f4-e3d44a68ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, ConcatDataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "923b3b5c-d071-4902-ac17-61647c7b11f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fffc35f4-d80b-4997-805d-130aaff531ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mRaceDataset\u001b[39;00m(\u001b[43mDataset\u001b[49m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, folder_path, seq_len=\u001b[32m32\u001b[39m, stride=\u001b[32m1\u001b[39m, dilation=\u001b[32m1\u001b[39m):\n\u001b[32m      3\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/metadata.json\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[31mNameError\u001b[39m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# PyTorch Dataset for Loading Supervised Training data for Mariokart DS\n",
    "class RaceDataset(Dataset):\n",
    "    def __init__(self, folder_path, seq_len=32, stride=1, dilation=1):\n",
    "        # Metadata stores the mean, std, min/max, and other data required for feature scaling\n",
    "        with open(f\"{folder_path}/metadata.json\", 'r') as f:\n",
    "            self.metadata: Metadata = json.load(f)\n",
    "        \n",
    "        self.obs_data = np.memmap(f\"{folder_path}/samples.dat\", dtype=np.float32, mode=\"r\").reshape(-1, len(self.metadata['mean']))\n",
    "        self.act_data = np.memmap(f\"{folder_path}/targets.dat\", dtype=np.int32, mode=\"r\")\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        self.stride = stride\n",
    "        self.dilation = dilation\n",
    "        self.window_span = (seq_len - 1) * dilation + 1\n",
    "\n",
    "        self.valid_indices = range(0, len(self.obs_data) - self.window_span + 1, stride)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.valid_indices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        start_idx = self.valid_indices[idx]\n",
    "        \n",
    "        end_idx = start_idx + self.window_span\n",
    "        obs_seq = torch.from_numpy(self.obs_data[start_idx : end_idx : self.dilation])\n",
    "\n",
    "        if start_idx == 0:\n",
    "            future_prev_acts = torch.from_numpy(self.act_data[self.dilation - 1 : end_idx - 1 : self.dilation])\n",
    "            prev_act_seq = torch.cat([torch.tensor([0]), future_prev_acts])\n",
    "        else:\n",
    "            prev_act_seq = torch.from_numpy(self.act_data[start_idx - 1 : end_idx - 1 : self.dilation])\n",
    "\n",
    "        last_frame_idx = end_idx - 1\n",
    "        target = torch.tensor(self.act_data[last_frame_idx], dtype=torch.long)\n",
    "\n",
    "        return obs_seq, prev_act_seq, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e259596-ea05-4771-9231-363d9c029876",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = RaceDataset(\"private/training_data/rdp1_pikalex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b40cb37c-a632-4ce0-8ea2-eaf36120c0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/__/sv2tgq6x5276drzd9mfj145h0000gn/T/ipykernel_52447/1522883603.py:23: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /Users/runnerx/miniforge3/conda-bld/libtorch_1764705037409/work/torch/csrc/utils/tensor_numpy.cpp:212.)\n",
      "  obs_seq = torch.from_numpy(self.obs_data[start_idx : end_idx : self.dilation])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 3.4322e+02,  3.4489e+02,  3.5018e+02,  ...,  2.9297e-03,\n",
       "           2.9297e-03,  0.0000e+00],\n",
       "         [ 3.4321e+02,  3.4488e+02,  3.5017e+02,  ...,  5.9204e-03,\n",
       "           5.8594e-03,  0.0000e+00],\n",
       "         [ 3.4320e+02,  3.4487e+02,  3.5017e+02,  ...,  8.8196e-03,\n",
       "           8.7891e-03,  0.0000e+00],\n",
       "         ...,\n",
       "         [ 4.2706e+02,  4.0041e+02,  3.8057e+02,  ...,  5.9900e+00,\n",
       "           4.1878e+00, -1.4964e-02],\n",
       "         [ 4.3273e+02,  4.0500e+02,  3.8431e+02,  ...,  4.7621e+00,\n",
       "           3.2282e+00, -1.2547e-02],\n",
       "         [ 4.3873e+02,  4.0987e+02,  3.8831e+02,  ...,  4.6677e+00,\n",
       "           3.1149e+00, -1.2407e-02]]),\n",
       " tensor([  0,   1,   1,   1,   1,   1,   1,  17, 273, 273, 273, 273, 273, 273,\n",
       "         273, 273, 273, 273, 273, 273, 273, 273, 273, 273, 257, 257, 289, 289,\n",
       "         289, 289, 289, 289]),\n",
       " tensor(289))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7583742b-a75c-4b70-a186-19b0cca8cf30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
